{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11757761,"sourceType":"datasetVersion","datasetId":7381214},{"sourceId":11758568,"sourceType":"datasetVersion","datasetId":7381684},{"sourceId":11783080,"sourceType":"datasetVersion","datasetId":7397884},{"sourceId":11783098,"sourceType":"datasetVersion","datasetId":7397902},{"sourceId":11783277,"sourceType":"datasetVersion","datasetId":7398036},{"sourceId":11785426,"sourceType":"datasetVersion","datasetId":7399622}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title LIBRARY\n!pip install pandas\n!pip install nympy\n!pip install tqdm\n!pip install torch\n!pip install torchvision\n!pip install matplotlib\n!pip install scikit-learn\n!pip install torchsummary\n!pip install tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T14:41:10.961960Z","iopub.execute_input":"2025-05-12T14:41:10.962158Z","iopub.status.idle":"2025-05-12T14:42:44.138675Z","shell.execute_reply.started":"2025-05-12T14:41:10.962133Z","shell.execute_reply":"2025-05-12T14:42:44.137712Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\n\u001b[31mERROR: Could not find a version that satisfies the requirement nympy (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for nympy\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.5.1+cu124)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# @title IMPORT_LIBRARY\nimport torch\nfrom torch.utils.data import TensorDataset # Import TensorDataset\nfrom torchvision.datasets  import CIFAR10\nimport torch.nn as nn\nfrom torchsummary import  summary\nfrom torchvision.transforms  import Compose , Resize,ToTensor\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import  DataLoader\nfrom tqdm import  tqdm  #Tạo thanh Progress Bar\nfrom sklearn.metrics import accuracy_score\n\n# @title EfficientNet-B0 MODEL\nimport torch\nimport torch.nn as nn\n\n# Swish Activation\nclass Swish(nn.Module):\n    def forward(self, x):\n        result = x * torch.sigmoid(x)\n        if torch.isnan(result).any():\n            raise ValueError(\"Gặp phải giá trị NaN trong kích hoạt Swish.\")\n        return result\n\n# SE Block (Squeeze and Excitation)\nclass SE_Block(nn.Module):\n    def __init__(self, in_channels, reduction=4):\n        super(SE_Block, self).__init__()\n        hidden_dim = in_channels // reduction\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),  # (C, H, W) -> (C, 1, 1)\n            nn.Conv2d(in_channels, hidden_dim, 1),\n            Swish(),\n            nn.Conv2d(hidden_dim, in_channels, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return x * self.se(x)\n\n# MBConv Block\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio, se_ratio=0.25):\n        super(MBConv, self).__init__()\n        hidden_dim = int(in_channels * expand_ratio)\n        self.has_residual = (stride == 1 and in_channels == out_channels)\n        self.has_se = se_ratio is not None and se_ratio > 0\n        self.expand_ratio = expand_ratio\n\n        # Expansion layer\n        self.expand = nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, 1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            Swish()\n        ) if expand_ratio != 1 else nn.Identity()\n\n        # Depthwise convolution layer\n        self.depthwise = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            Swish()\n        )\n\n        # Squeeze-and-Excitation block\n        if self.has_se:\n            self.se = SE_Block(hidden_dim, reduction=int(1 // se_ratio))\n\n        # Project layer\n        self.project = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, x):\n        out = self.expand(x)\n        out = self.depthwise(out)\n        if self.has_se:\n            out = self.se(out)\n        out = self.project(out)\n        if self.has_residual:\n            out = out + x  # Skip connection\n        return out\n\n\n# EfficientNet-B0\nclass My_EfficientNet_B0(nn.Module):\n    def __init__(self, num_classes):\n        super(My_EfficientNet_B0, self).__init__()\n        base_channels = 32\n        self.steam = nn.Sequential(\n            nn.Conv2d(3, base_channels, 3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(base_channels),\n            Swish()\n        )\n\n        in_channels = base_channels\n        layers = []\n\n        config = [\n            (1, 16, 1, 3, 1),\n            (6, 24, 2, 3, 2),\n            (6, 40, 2, 5, 2),\n            (6, 80, 3, 3, 2),\n            (6, 112, 3, 5, 1),\n            (6, 192, 4, 5, 2),\n            (6, 320, 1, 3, 1)\n        ]\n\n        # Chỉnh sửa cấu hình để đảm bảo sự phù hợp về kênh\n        for expand_ratio, out_channels, num_layers, kernel_size, stride in config:\n            for i in range(num_layers):\n                s = stride if i == 0 else 1\n                layers.append(MBConv(in_channels, out_channels, kernel_size, s, expand_ratio))\n                in_channels = out_channels\n\n        self.body = nn.Sequential(*layers)\n\n        self.head = nn.Sequential(\n            nn.Conv2d(in_channels, 1280, 1, bias=False),\n            nn.BatchNorm2d(1280),\n            Swish(),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(1280, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.steam(x)\n        x = self.body(x)\n        x = self.head(x)\n        return x\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:45:15.279970Z","iopub.execute_input":"2025-05-12T15:45:15.280599Z","iopub.status.idle":"2025-05-12T15:45:15.295243Z","shell.execute_reply.started":"2025-05-12T15:45:15.280572Z","shell.execute_reply":"2025-05-12T15:45:15.294672Z"},"editable":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\n\n# @title IMPORT_LIBRARY\nimport torch\nfrom torch.utils.data import TensorDataset # Import TensorDataset\nfrom torchvision.datasets  import CIFAR10\nimport torch.nn as nn\nfrom torchsummary import  summary\nfrom torchvision.transforms  import Compose , Resize,ToTensor\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import  DataLoader\nfrom tqdm import  tqdm  #Tạo thanh Progress Bar\nfrom sklearn.metrics import accuracy_score\n\n\n# @title MODEL RESNET 18\nclass BasicBlock(nn.Module):\n  def __init__(self, in_channels,out_channels, stride=1):\n    super(BasicBlock, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn1 = nn.BatchNorm2d(out_channels)\n    self.relu = nn.ReLU(inplace=False)\n    self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3, stride=1,padding=1,bias=False)\n    self.bn2 = nn.BatchNorm2d(out_channels)\n    self.shortcut = nn.Sequential()\n    if stride != 1 or in_channels != out_channels:\n      self.shortcut = nn.Sequential(\n          nn.Conv2d(in_channels,out_channels, kernel_size=1, stride=stride,bias = False),\n          nn.BatchNorm2d(out_channels)\n\n      )\n  def forward(self, x):\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)  # ReLU should not modify the tensor in-place\n    out = self.conv2(out)\n    out = self.bn2(out)\n    out = self.relu(out)  # Again, no in-place operation\n\n    out = out + self.shortcut(x)\n    out = self.relu(out)\n    return out\n\n\nclass Resnet18(nn.Module):\n  def __init__(self, num_classes = 10):\n    super(Resnet18,self).__init__()\n    self.in_channels = 64\n    self.conv1 = nn.Conv2d(in_channels=3,out_channels=64, kernel_size=3, stride=1,padding=1, bias=False) #Giu nguyen size vi Cfar size be\n    self.bn1 = nn.BatchNorm2d(64)\n    self.relu = nn.ReLU(inplace=False)\n    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n    self.layer1 = self.make_layer(64,BasicBlock, 2,   stride=1)\n    self.layer2 = self.make_layer(128,BasicBlock, 2,  stride=2)\n    self.layer3 = self.make_layer(256,BasicBlock, 2,  stride=2)\n    self.layer4 = self.make_layer(512,BasicBlock, 2,  stride=2)\n\n    self.avg = nn.AdaptiveAvgPool2d((1,1))\n    self.fc = nn.Linear(512, num_classes)\n\n\n  def make_layer(self, out_channels,block, num_block, stride):\n    strides = [stride] + [1]*(num_block-1)\n    layer = []\n    for stride in strides:\n      layer.append(block(self.in_channels,out_channels, stride))\n      self.in_channels = out_channels\n\n    return nn.Sequential(*layer)\n\n  def forward(self,x):\n    out = self.conv1(x)\n    out = self.bn1(out)\n    out = self.relu(out)\n\n    out = self.maxpool(out)\n\n    out = self.layer1(out)\n    out = self.layer2(out)\n    out = self.layer3(out)\n    out = self.layer4(out)\n\n    out = self.avg(out)\n    out = out.view(out.size(0),-1)\n    out = self.fc(out)\n    return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:44:14.595232Z","iopub.execute_input":"2025-05-12T15:44:14.596204Z","iopub.status.idle":"2025-05-12T15:44:14.609765Z","shell.execute_reply.started":"2025-05-12T15:44:14.596173Z","shell.execute_reply":"2025-05-12T15:44:14.608927Z"},"editable":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import accuracy_score\nimport sys\nsys.path.append('/kaggle/input/dataclassification')\n \nfrom Dataset_Classification import Falling_Dataset4Clss\nimport torch\nimport os\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import  DataLoader\nfrom torchvision.transforms  import Compose , Resize,ToTensor,RandomAffine, ColorJitter,Normalize\nimport  torch.nn as nn\nfrom tqdm import  tqdm  #Tạo thanh Progress Bar\nfrom torch.utils.tensorboard import SummaryWriter\ndef compute_and_save_soft_labels(model_teacher, train_dataset, save_path, batch_size=64, T=2):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_teacher.to(device)\n    model_teacher.eval()\n\n    dataloader = DataLoader(\n        dataset=train_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=2,\n        drop_last=False,\n        pin_memory=True\n    )\n\n    all_soft_labels = []\n\n    with torch.no_grad():\n        for images, _ in tqdm(dataloader, desc=\"Computing soft labels in memory\"):\n            images = images.to(device, non_blocking=True)\n            outputs = model_teacher(images)\n            soft = torch.softmax(outputs / T, dim=1)\n            all_soft_labels.append(soft.cpu())\n            torch.cuda.empty_cache()\n\n\n    soft_labels_tensor = torch.cat(all_soft_labels, dim=0)\n    torch.save(soft_labels_tensor, save_path)\n    print(f\"Saved soft labels to: {save_path}\")\n\n\n# --------- STEP 2: Train student với soft labels đã lưu ----------\ndef train_with_KD_soft_labels(model_student, train_dataset, test_dataloader, soft_labels_path,\n                              check_point, num_epochs, pathsave_model, model_name, tensorboard_name, T=2):\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_student = model_student.to(device)\n    writer = SummaryWriter(log_dir=pathsave_model, comment=model_name, filename_suffix=tensorboard_name)\n\n    optimizer = torch.optim.Adam(model_student.parameters(), lr=1e-3, betas=(0.9, 0.999))\n    criterion = nn.CrossEntropyLoss()\n\n    if check_point is not None:\n        checkpoint = torch.load(check_point)\n        start_epoch = checkpoint['epoch']\n        model_student.load_state_dict(checkpoint['model'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n    else:\n        start_epoch = 0\n\n    soft_labels = torch.load(soft_labels_path)  # (N, num_classes)\n\n    train_loader = DataLoader(\n        dataset=train_dataset,\n        batch_size=64,\n        shuffle=False,\n        num_workers=2,\n        drop_last=False,\n        pin_memory=True\n    )\n\n    best_accuracy = 0\n    num_iters = len(train_loader)\n    for epoch in range(start_epoch, num_epochs):\n        model_student.train()\n        progress_bar =  tqdm(train_loader)\n\n        for i, (images, labels) in enumerate(progress_bar):\n            images = images.to(device)\n            labels = labels.to(device)\n            soft_targets = soft_labels[i * 64:(i + 1) * 64].to(device)\n\n            outputs = model_student(images)\n\n            ce_loss = criterion(outputs, labels)\n            kd_loss = nn.KLDivLoss(reduction='batchmean')(\n                torch.log_softmax(outputs / T, dim=1), soft_targets\n            )\n            loss = 0.85 * ce_loss + 0.15 * (T ** 2) * kd_loss\n            progress_bar.set_description('Epoch {}/{}, Iteration {}/{}, Loss {:.3f}'.format( epoch+1, num_epochs, i+1, num_iters, loss))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            writer.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + i)\n\n        # Validation\n        model_student.eval()\n        all_preds, all_gts = [], []\n\n        with torch.no_grad():\n            for images, labels in test_dataloader:\n                images = images.to(device)\n                labels = labels.to(device)\n                outputs = model_student(images)\n                preds = torch.argmax(outputs, dim=1)\n                all_preds.extend(preds.cpu().numpy())\n                all_gts.extend(labels.cpu().numpy())\n\n        acc = accuracy_score(all_gts, all_preds)\n        writer.add_scalar('Val/Accuracy', acc, epoch)\n\n        # Save model\n        checkpoint = {\n            'epoch': epoch + 1,\n            'model': model_student.state_dict(),\n            'optimizer': optimizer.state_dict()\n        }\n        torch.save(checkpoint, f'{pathsave_model}/last_cnn.pt')\n\n        if acc > best_accuracy:\n            torch.save(checkpoint, f'{pathsave_model}/best_cnn.pt')\n            best_accuracy = acc\n\n        print(f\"Epoch {epoch + 1} | Accuracy: {acc:.4f} | Best: {best_accuracy:.4f}\")\nfrom torchvision import models\ndef make_dataset(type_data):\n  if type_data == 'train':\n    train_transform = Compose([\n          # Biến đổi hình học\n          RandomAffine(\n              degrees=(-5, 5),\n              translate=(0.05, 0.05),\n              scale=(0.85, 1.15),  # scale quanh 1, tránh thu nhỏ quá nhiều\n              shear=5              # shear nhẹ\n          ),\n          # Biến đổi màu sắc\n          ColorJitter(\n              brightness=0.1,\n              contrast=0.2,\n              saturation=0.2,\n              hue=0.05\n          ),\n          Resize((224, 224)),\n          ToTensor(),\n          # Chuẩn hóa theo ImageNet\n          Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225]\n          )\n    ])\n  else:\n    train_transform = Compose([\n          Resize((224, 224)),\n          ToTensor(),\n          # Chuẩn hóa theo ImageNet\n          Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225]\n          )\n    ])\n\n\n  dataset = Falling_Dataset4Clss(\n      root='/kaggle/input/classification-dataset',\n      type_data = type_data,\n      transform = train_transform\n  )\n\n  return dataset\n\nif __name__ == '__main__':\n    import torch\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n    model_vit = models.vit_b_16(pretrained=False)\n    model_vit.heads.head = nn.Linear(model_vit.heads.head.in_features, 2)\n\n    # 2. Load checkpoint và trích xuất state_dict\n    checkpoint = torch.load('/kaggle/input/vit-hehe/best_cnn.pt', map_location='cpu')\n    model_vit.load_state_dict(checkpoint['model'])\n    train_dataset = make_dataset('train')\n    # 4. Đưa model sang thiết bị và chuyển sang eval mode\n    model_vit = model_vit.to(device)\n    model_vit.eval()\n    # compute_and_save_soft_labels(model_vit, train_dataset,\n    #                              'D:\\BTL_ThucTapCS/soft_labels.pt', batch_size=64,\n    #                              T=2)\n\n    test_dataset = make_dataset('valid')\n    test_dataloader = DataLoader(\n        dataset=test_dataset,\n        batch_size=64,\n        num_workers=2,\n        drop_last=False,\n        pin_memory=True\n\n    )\n    # Load checkpoint vào CPU\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    # Load vào mô hình\n    model_res = Resnet18(num_classes = 2)\n    checkpoint = torch.load('/kaggle/input/resnet-ahihi/best_cnn.pt', map_location='cpu')\n    model_res.load_state_dict(checkpoint['model'])\n    \n    # Chỉ chuyển sang GPU nếu còn đủ bộ nhớ\n    model_res.to(device)\n\n    train_with_KD_soft_labels(\n        model_student = model_res,\n        train_dataset = train_dataset,\n        test_dataloader = test_dataloader,\n        soft_labels_path ='/kaggle/input/soft-labels/soft_labels.pt',\n        check_point = None,\n        num_epochs = 30,\n        pathsave_model = '/kaggle/working/',\n        model_name = 'res_withKD',\n        tensorboard_name= 'run1',\n        T=2\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:46:44.170027Z","iopub.execute_input":"2025-05-12T15:46:44.170296Z","iopub.status.idle":"2025-05-12T15:46:53.653947Z","shell.execute_reply.started":"2025-05-12T15:46:44.170275Z","shell.execute_reply":"2025-05-12T15:46:53.652761Z"},"editable":false},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2583731046.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('/kaggle/input/vit-hehe/best_cnn.pt', map_location='cpu')\n/tmp/ipykernel_31/2583731046.py:213: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('/kaggle/input/resnet-ahihi/best_cnn.pt', map_location='cpu')\n/tmp/ipykernel_31/2583731046.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  soft_labels = torch.load(soft_labels_path)  # (N, num_classes)\nEpoch 1/20, Iteration 17/335, Loss 0.674:   5%|▍         | 16/335 [00:06<02:12,  2.40it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2583731046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mmodel_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     train_with_KD_soft_labels(\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mmodel_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2583731046.py\u001b[0m in \u001b[0;36mtrain_with_KD_soft_labels\u001b[0;34m(model_student, train_dataset, test_dataloader, soft_labels_path, check_point, num_epochs, pathsave_model, model_name, tensorboard_name, T)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train/Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15}]}